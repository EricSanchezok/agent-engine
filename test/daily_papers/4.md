### XFINBENCH：用于复杂金融问题求解与推理的 LLM 基准

**信号源**：新加坡管理大学计算与信息系统学院；复旦大学可信任具身智能研究院  
**论文链接**：https://arxiv.org/abs/2508.15861

---

#### 一句话总结  
作者构建了首个同时覆盖文本、表格与图像的研究级金融数据集 XFINBENCH，并利用 18 个主流模型实证揭示：当前 LLM 在跨期推理与情景规划等核心金融能力上仍显著落后于人类专家。

---

#### 论文摘要  
金融决策需要复杂推理、多模态信息处理和扎实的专有知识。为系统评估 LLM 的金融能力，作者提出 XFINBENCH——共 4,235 道题目（来自 3 本研究生教材），涵盖文本、表格与图像三种模态，并细分五项关键能力：  

1. 术语理解 (Terminology Understanding)  
2. 时间推理 (Temporal Reasoning)  
3. 未来预测 (Future Forecasting)  
4. 情景规划 (Scenario Planning)  
5. 数值建模 (Numerical Modelling)

基准包含判断正误、选择题、数值计算三类任务，另构建 3,032 条金融术语知识库辅助可检索增强实验。作者评测 18 款模型：最佳纯文本模型 o1 准确率 67.3%，较人类专家（79.8%）低 12.5 pct；含视觉数据时表现最佳的 claude-3.5-sonnet 仅 64.1%。误差分析指出，计算过程中的四舍五入误差与图表解析“视觉失明”是失败主因。XFINBENCH 因而为金融领域 LLM 研究提供了高难度、系统化的评测平台。

---

#### 核心方法  
* **数据构建**  
  * 选取 3 本研究生教材课后题；经 OCR 与人工筛选得到 2,018 道原始题。  
  * 采用「生成-校验」流程：先用 GPT-4o 将开放题转写为有唯一答案的判断题 / 选择题 / 计算题，再由人工三轮验证，最终保留 4,235 题。  
  * 每题标注 1–2 个能力标签，并链接 1–3 个相关金融术语；多模态题保留原图表或表格。  

* **评测体系**  
  * 对 18 个模型统一使用 Chain-of-Thought (CoT)；数值计算任务另测 Program-of-Thought (PoT)，同时报告严格匹配与 ±0.5% 容差 (Acc_ERR@5) 两项指标。  
  * 构建人类专家基线（硕士背景，闭卷）——综合准确率 79.8%。  

* **知识库检索增强**  
  * 比较 BM25、Ada Embedding 及理想 “Oracle” 三种注入策略，量化对不同模型与能力的影响。  

* **误差标注**  
  * 对 400 条计算题与 100 条视觉题进行人工标注，归纳“舍入误差”“公式误用”“视觉失明”等高频失误模式。

---

#### 关键实验结果  
| 指标 | 纯文本最佳 (o1) | 多模态最佳 (claude-3.5-sonnet) | 人类专家 |
|------|----------------|--------------------------------|----------|
| 总准确率 | **67.3%** | **64.1%** | **79.8%** |
| 术语理解 | 88.9% | 86.4% | 91.0% |
| 时间推理 | 59.1% | 43.4% | 79.5% |
| 情景规划 | 60.1% | 47.2% | 75.8% |

* **PoT 并非万能**：对多数模型，PoT 代码执行率低导致计算题表现反而下降。  
* **视觉题难度陡增**：GPT-4o 在含图题中 35% 错误归因于无法正确识别曲线交点或坐标位置（视觉失明）。  
* **小模型最受益于知识注入**：Oracle 场景下，Llama-3.1-8B 总分提升约 3 pct，术语理解提升超过 10 pct；GPT-4o 反而偶现“过度依赖”导致推理偏差。  

---

#### 结论与启示  
1. **可靠金融 LLM 尚需突破**：跨期推理与情景规划是当前主要瓶颈。  
2. **跨模态解析待攻关**：需融合低层视觉特征与高层金融语义以缓解“视觉失明”。  
3. **数值推理稳定性**：长链计算易积累舍入误差，结合程序化推理与自检或能改善。  
4. **轻量模型 + 外部知识**：在算力受限场景，检索增强依旧有效；大模型则亟需更精细的知识筛选与推理控制。  
5. **研究生态**：XFINBENCH 有望成为金融 NLP/MMLU 新标杆，推动面向风控、定价、合规的下一代金融智能体研究。

---

#### 限制与未来工作  
* 数据集规模（4k+）相较常规阅读理解数据仍偏小；且目前仅含英文内容，后续可扩展多语言、多市场。  
* 评测依赖固定输出格式，模型若不遵守格式会被判错；探索更鲁棒的评测脚本值得尝试。  

---

#### 参考指标  
* 数据集：4,235 题（判断 1,795；选择 761；计算 1,679）  
* 知识库：3,032 术语 / 1,766 唯一定义  
* 评测模型：18 个（9 多模态 + 9 纯文本）

---

> **总体评价**：XFINBENCH 设计严谨、覆盖面广，是当前衡量 LLM 复杂金融能力最具挑战的公开基准之一，可为学术与产业界提供重要参考。