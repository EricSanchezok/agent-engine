### Improving LLMs for Machine Translation Using Synthetic Preference Data  
**信号源：** University of Ljubljana, Faculty of Computer and Information Science  

**一句话总结**  
通过自动生成“优/劣”翻译对并用直接偏好优化（DPO）微调，仅用 9B 参数模型即可在英语→斯洛文尼亚翻译上逼近甚至在部分场景超越更大模型，显著减少语言和截断错误。  

**论文摘要**  
作者针对资源稀缺的斯洛文尼亚语机器翻译，提出一种无需人工标注的改进流程：先用两种开源 LLM（GaMS-9B-Instruct 与 EuroLLM-9B-Instruct）翻译英文维基和新闻文章，再依据启发式规则与 COMET 评分自动标出优劣翻译对，最后用 DPO 训练 GaMS-9B-Instruct。新模型在 SloBench 公开基准及未见过的维基/新闻文章上，都明显优于原始模型，并能稳定避免输出非目标语或文本截断。该方法语言无关，可推广到其他低资源语言。  

**核心方法**  
* 方法框架：  
  1. 双模型翻译：用两个独立 LLM 为同一英文文本生成两个斯洛文尼亚语候选。  
  2. 质量判别：  
     • 规则筛除明显错误（非目标语言、截断、格式前缀）。  
     • 对剩余候选用 COMET 评分，若分差 ≥ 0.05，则高分为“优”，低分为“劣”。  
  3. 构建偏好数据集：融合规则错误对与 COMET 质量对，得到约 3.5 万条“优/劣”配对。  
  4. DPO 微调：以 GaMS-9B-Instruct 为基线，在偏好数据上做 Direct Preference Optimization，通过最小化“优/劣”对数似然比直接对模型进行偏好对齐。  

* 技术细节：  
  1. 错误检测自动化  
     • 语言识别：FastText 断定输出是否为斯洛文尼亚语。  
     • 截断检测：若译文长度不足原文 50% 即判定为截断。  
     • 格式噪声：程序化添加／去除“Slovene translation:” 等前缀构造显式偏好对。  
  2. 参数高效训练  
     • 采用 LoRA，仅微调少量参数即可适配 9B 模型。  
     • 使用 DeepSpeed ZeRO-Stage-2 + Gradient Checkpointing，在 16×A100 GPU 上完成 3 epoch 训练。  
  3. 超参选择  
     • 网格搜索 β∈{0.1, 0.2} 与学习率∈{1e-6, 4e-7, 1e-7}，最终选 β = 0.1, lr = 1e-6（验证损失最低 0.255）。  

**实验成果**  
* **维基 & 新闻翻译质量大幅提升**：在 500 篇未见维基文章和 CC-News 文章上，新模型 COMET 分别提升至 0.757 / 0.715，较基线 GaMS-9B-Instruct 提高约 0.04；同时将“非目标语言+截断”综合错误率从 13 % 降至 0.8 %。  
* **公开基准逼近大模型**：在 SloBench 英→斯洛文尼亚任务中，GaMS-9B-DPO-Translator 的平均 BLEU 从 0.277 提升至 0.281，总体得分与 3 倍参数量的 GaMS-27B-Instruct 接近，与同参数量的 EuroLLM-9B-Instruct 大体相当。  

**总结与反思**  
* 结果总结：论文展示了一条低成本、自动化的机器翻译增益路线——利用双 LLM 互译 + 自动优劣判别 → DPO 微调，可显著减少低资源语言翻译中的粗暴错误，并带来稳健的质量提升。  
* 局限性：  
  • 偏好数据主要来源于维基和新闻，风格/领域覆盖仍有限；  
  • 评估依赖自动指标与合成错误检测，对语义细微差异的人工验证不足；  
  • 仅验证 9B 规模，迁移到更大模型或其他语言需重新调参与资源投入。  
* 前沿见解：  
  • 研究方向：a) 将“多模型互译+自动筛选”扩展为多语言、多域 Curriculum DPO；b) 结合可微指标（如 COMET 作为奖励函数）尝试 GRPO 或混合 RL 策略；c) 在数据稀缺领域（方言、专业术语）快速自举高质量译文资源。  
  • 工业应用：可为本地政府、教育及媒体批量翻译公共语料，节省商业 API 费用；同法可用于企业内部文档跨语迁移，从而构建专属多语知识库。  
  • 领域影响：证明了“偏好对齐”不仅适用于对话质量，同样能解决传统 NMT 模型难以捕捉的细粒度翻译偏好，或将促成新一代“偏好驱动”机器翻译体系，把 RLHF/DPO 方法正式引入 MT 主流流程。