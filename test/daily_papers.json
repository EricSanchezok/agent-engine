{
  "date": "20250820",
  "papers": [
    {
      "authors": [
        "Josh Barua",
        "Seun Eisape",
        "Kayo Yin",
        "Alane Suhr"
      ],
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "content_id": "9623ee1e76161ca514983413eeb7d8c54a3b9364e7d5b45ae7d73ab1ec7e74d2",
      "paper_id": "fe3a68f169d896e8e7b38ed245c63cf1f44964cac51767935c86cb43b2210b7f",
      "pdf_url": "http://arxiv.org/pdf/2508.14828v1",
      "report": "### Towards Source-Free Machine Unlearning  \n\n**一句话总结**  \n作者首次针对线性（及混合线性）分类器，在“源数据不可用”场景下，仅凭已训练模型与待删除样本，即可高效并带有理论保证地完成实例级机器遗忘。  \n\n---\n\n#### 论文摘要  \n随着隐私法规收紧，模型在用户要求下删除特定训练信息的需求激增。现有机器遗忘方法大多仍需访问剩余训练数据，但实际部署中往往已无法再次存储或调用这些数据。论文提出“Source-Free Machine Unlearning”：在完全看不到剩余数据的情况下执行遗忘的通用框架。作者聚焦 ℓ₂ 正则化的线性模型及可微凸损失函数，通过对“剩余数据” Hessian 的近似估计，构造一次近似 Newton 更新来移除指定样本对参数的影响；并给出参数不可区分性的显式上界。实验证明，在 CIFAR-10/100、Stanford Dogs、Caltech-256 等数据集上，新方法几乎与重新训练等价，并显著优于现有源数据缺失的遗忘技术。  \n\n---\n\n#### 核心方法  \n\n1. **问题设定**  \n   * 已训练参数 \\(w^\\star\\)，待遗忘数据集 \\(D_f\\)；剩余训练集 \\(D_r\\) 不再可用。  \n   * 目标：产出 \\(w_{\\text{uf}}\\)，使其在 \\(D_f\\) 上“遗忘”，同时在 \\(D_r\\) 与测试集上的表现接近用 \\(D_r\\) 重新训练的模型。  \n\n2. **Hessian 近似**  \n   * 在 \\(w^\\star\\) 周围采样多组小扰动 \\(\\delta w\\)，分别计算遗忘集上的损失差 \\(\\delta L_f\\)。  \n   * 假设在局部邻域内 \\(\\delta L_f \\approx \\delta L_r\\)，将  \n     \\[\n       f_i(H)=\\tfrac12\\delta w_i^\\top H\\delta w_i-\\nabla_f^\\top\\delta w_i-\\delta L_f(\\!w_i)\n     \\]  \n     的平方残差最小化：\\(\\Psi(H)=\\frac1m\\sum_i f_i(H)^2\\)。  \n   * 令 \\(H\\succeq0\\) 并将最小化问题写成半定规划 (SDP)，得到保正定的 Hessian 估计 \\(\\hat H_r\\)。  \n\n3. **一次参数更新**  \n   * 用估计量执行  \n     \\[\n       w_{\\text{uf}} = w^\\star - \\hat H_r^{\\!-1}\\nabla_f + \\sigma\\varepsilon,\n     \\]  \n     其中 \\(\\varepsilon\\sim\\mathcal N(0,I)\\) 用于抵消可能的信息泄漏。  \n   * 论文推导了 \\(\\|\\nabla L(w_{\\text{uf}},D_r)\\|\\) 的显式上界，表明维度增大时误差收敛、遗忘更充分。  \n\n4. **扩展到深度网络**  \n   * 采用“混合线性”策略：冻结大部分网络，仅线性化末若干层（NTK 近似），将深度模型退化为上述线性情形，再应用同样的 Hessian 估计与更新步骤。  \n\n---\n\n#### 实验结果  \n\n| 数据集 | 模型设定 | 重训 (Test) | Unlearned(+) | Unlearned(-) | MIA ↓ |\n|-------|----------|------------|--------------|--------------|-------|\n| CIFAR-10 | 线性 | 72% | 70.3% | 70.0% | 51.5% |\n| CIFAR-100 | 线性 | 56.0% | 49.8% | 51.6% | 51.8% |\n| Stanford Dogs | 线性 | 59.3% | 54.6% | 55.0% | 50.9% |\n| Caltech-256 | 线性 | 54.4% | 47.6% | 49.4% | 50.6% |\n\n* Unlearned(+)：在可访问 \\(D_r\\) 时用真 Hessian 进行遗忘。  \n* Unlearned(−)：本文方法，仅用 \\(w^\\star\\)+\\(D_f\\)。  \n\n主要观察：  \n• 在四个数据集上，Unlearned(−) 的测试性能距离重训模型差距通常小于 2–3%，显著好于现有源数据缺失方法 (>15% 差距)。  \n• MIA 分数从 ~59% 降至约 50%，表明模型已无法区分被删样本是否参与训练，实现有效遗忘。  \n\n---\n\n#### 总结与反思  \n\n• **贡献**：提出首个针对线性及混合线性分类器、带有显式理论保证的源数据缺失机器遗忘算法；通过随机微扰与 SDP 估计 Hessian，使零样本遗忘成为可能。  \n• **局限**：  \n  – 依赖凸损失与 Hessian 可正定假设；端到端非凸网络仍需线性化近似。  \n  – SDP 在超高维情形计算／存储成本较高；作者建议使用对角或低秩近似作为未来工作。  \n  – 随遗忘样本比例增大，理论界限变宽，实验亦显示性能下降。  \n• **前沿展望**：  \n  – 将该框架扩展到大规模语言模型、扩散模型等非线性场景；结合 Kronecker 或低秩 Hessian 逼近可缓解计算瓶颈。  \n  – 为工业场景提供可落地的“Forget API”，满足 GDPR“被遗忘权”诉求。  \n  – 参数不可区分性上界为遗忘质量提供了可量化指标，有望成为后续隐私合规审计参考标准。",
      "timestamp": "20250820T1622",
      "title": "Long chainofthought reasoning across languages"
    },
    {
      "authors": [
        "Dario Vajda",
        "Domen Vreš",
        "Marko Robnik-Šikonja"
      ],
      "categories": [
        "cs.CL"
      ],
      "content_id": "52ff757e6d4595fd4a0b2b64df33678e994665ed4768c7e17490f03b7db9a7be",
      "paper_id": "ac3c4b0f606b0258e19813c071c08c20461599afbfeab2d72b3f8e1e1c241a9f",
      "pdf_url": "http://arxiv.org/pdf/2508.14951v1",
      "report": "### FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy  \n**信号源：** 上海交通大学  \n\n---\n\n#### 一句话总结  \n“先流再模仿”(FBI) 通过动态视觉-触觉融合与一步 Shortcut 扩散策略，让机器人即使没有真实触觉传感器，也能以约 20 Hz 实时完成高难度翻转和推握操作；在总体平均上较最佳基线提升约 16 %–18 %，在最难的翻转任务中提升超过 20 %。  \n\n---\n\n#### 论文摘要  \n复杂接触动力学与局部可见性长期制约单手灵巧操作。FBI 框架以“动态融合”思路将两帧点云的运动流与触觉信号建立因果联系：  \n1. **Flow2Tactile** 模块先由点云流预测触觉（可选地用真实传感器微调）；  \n2. 预测/实测触觉与视觉特征经 **Transformer** 融合；  \n3. **一步 Shortcut Diffusion Policy** 直接输出完整动作序列，实现实时控制。  \n\n在两类自定义任务（翻转、推移）与 Adroit 基准三任务中，FBI 在仿真和真实环境均超越四个最新基线，平均成功率提升 16.6 %（Vision-Only）至 18.4 %（Visuotactile），其中翻转任务最高提升 21.4 %。  \n\n---\n\n#### 核心方法  \n* **整体流程**  \n  1. **多模态编码**  \n     - 两帧关节状态、点云与触觉读数分别经 MLP 编码为状态、视觉及触觉特征。  \n  2. **动态触觉推断**  \n     - Flow2Tactile 先用一步 Shortcut 模型预测点云运动流，再在 456 个手掌关键点上搜索生成稠密二值接触图，可在 “纯视觉” 模式中替代真实传感器。  \n  3. **Transformer 融合**  \n     - 以视觉特征为模板、触觉特征为查询，输出联合视触特征。  \n  4. **一步扩散策略**  \n     - Shortcut Policy 仅一次前向传播即可把高斯噪声动作去噪成完整动作序列，带来毫秒级推理。  \n\n* **关键技术细节**  \n  1. **Flow2Tactile 精度**：融合运动流与手部关键点位置，触觉预测准确率达 85.5 %。  \n  2. **稠密二值触觉表示**：每个关键点仅判定“接触/未接触”，简化学习并便于传感器映射，保证仿真-现实一致性。  \n  3. **Shortcut Policy 训练**：同时最小化流匹配与自一致损失，使原需多步去噪的扩散过程收敛到单步；单步去噪仅 ≈10 ms，整体模型推理 ≈34 ms。  \n\n---\n\n#### 实验成果  \n* **成功率显著提升**  \n  - 仿真五任务平均成功率：64.7 %（Vision-Only）/66.5 %（Visuotactile），分别比基线 DP3 高 16.6 % 与 18.4 %；在最困难的翻转任务提升 19.3 %–21.4 %。  \n  - 真实机器人实验平均成功率：33.5 %（Vision-Only）/35.0 %（Visuotactile），较最佳基线 ManiCM 提高约 15 %–16.5 %。  \n\n* **实时控制效率**  \n  - RTX 4090 上，模型推理 34 ms（其中 Flow2Tactile 17 ms，策略生成 15 ms），加上环境交互总体约 51 ms，可实现 ≈20 Hz 闭环控制；相比 DP3 138 ms、10 步 DDIM 261 ms 延迟显著降低。  \n\n---\n\n#### 总结与反思  \n* **成果**：FBI 以“先预测运动流→推断触觉→一步出动作”的链式设计，将视觉与触觉动态耦合，显著增强复杂接触场景下的稳定性与泛化性，并证实“无触觉硬件也可享触觉收益”的可行性。  \n* **局限**：  \n  - 依赖点云质量，强遮挡或深度噪声会削弱 Flow2Tactile 准确性；  \n  - 二值接触无法表达细微力变化，限制极精细操作；  \n  - 训练需大量成功示例（≈5000 条/物体），数据采集成本高。  \n* **前沿展望**：  \n  1. 将隐式触觉估计扩展到力-矩连续空间，结合语义意图实现多任务通用操控；  \n  2. 对成本敏感的工业手可少装或无装触觉硬件，借视觉补偿完成高精度装配、分拣等任务；  \n  3. 一步扩散结合多模态动态融合为实时端到端策略提供新范式，有望推动视-触感知从“静态拼接”迈向“因果建模”。",
      "timestamp": "20250820T1424",
      "title": "Improving llms for machine translation using synthetic preference data"
    },
    {
      "authors": [
        "Shuaijie She",
        "Yu Bao",
        "Yu Lu",
        "Lu Xu",
        "Tao Li",
        "Wenhao Zhu",
        "Shujian Huang",
        "Shanbo Cheng",
        "Lu Lu",
        "Yuxuan Wang"
      ],
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "content_id": "393d333f5283f34cb1e9f15d2de489e56fc393c8873292e0109707bff66c3468",
      "paper_id": "d4f63db8473151d622f49085a50818011b4d25cf19016a158de8723a83311cd6",
      "pdf_url": "http://arxiv.org/pdf/2508.14460v1",
      "report": "### Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization\n**信号源：** International Digital Economy Academy、Emdoor Collaborative Laboratory  \n\n---\n\n#### 一句话总结  \nLPO 通过“绝对值损失 + 偏移约束 + 可控梯度分离”三板斧，缓解了 DPO 的过拟合与崩溃难题，为大模型偏好对齐提供了更稳、更易调的线性优化范式。  \n\n---\n\n#### 论文摘要  \n当前主流离线偏好对齐算法 DPO（Direct Preference Optimization）虽实现简洁稳定，但常出现过拟合与概率塌陷。作者提出线性偏好优化（LPO），用绝对差损失取代 DPO 的 log-sigmoid，并加入偏移约束与正向正则，从而解耦选中与拒绝样本的梯度，抑制过度下降；再借助直通估计器（STE）在计算图中分离梯度，引入可调系数 r₂ 线性控制拒绝概率的下降速度。实验覆盖通用文本、数学推理及语音合成三大场景，均显示 LPO 相较 SFT 明显提升，对 DPO 亦具备竞争力。作者已公开代码与模型。  \n\n---\n\n#### 核心方法\n* **框架要点**  \n  1. 将 DPO 的 log-sigmoid 损失替换为“选中 – 拒绝”绝对差，并做长度归一化；  \n  2. 在差值上施加固定偏移 μ，防止间隔过大，同时增加 λ·max(0, −x₁) 正向项，避免选中概率下降；  \n  3. 采用 STE 将选中与拒绝分支的梯度断开，再用 r₂ 独立缩放拒绝分支梯度，实现“可控拒绝”。  \n\n* **技术细节**  \n  - 绝对差损失实现梯度解耦，使两分支互不干扰，避免“拒绝梯度主导”；  \n  - 偏移 μ + 正向正则双管齐下提升稳定性；  \n  - r₂ 范围 0.05–3.0，可线性调节拒绝概率下降斜率。  \n\n---\n\n#### 实验成果\n* **通用任务（MT-Bench / AlignBench）**  \n  - 在 MT-Bench 上，相比 SFT 基线提升约 **6.37%**，与 DPO 表现相近；  \n  - 在 AlignBench 上总分提升约 **3.6%**，对“文本写作”“逻辑推理”等子项改进显著。  \n\n* **数学推理（GSM8K，零样本）**  \n  - LPO 得分 **88.86**，较 SFT 提升 **4.71** 分，较 DPO 高 **6.52** 分，并超越官方 Qwen2.5-Instruct（87.19）。  \n\n* **语音合成（TTS）**  \n  - 在 UniTTS 基线下，LPO 使“情感表达”与“保真度”进一步提升，稳定性轻微下降。  \n\n* **语音识别（ASR）**  \n  - 在 AISHELL-1 与 LibriSpeech 上，LPO 均显著降低 CER/WER，验证了长序列场景下的有效性。  \n\n---\n\n#### 总结与反思\n* **贡献概括**  \n  LPO 针对 DPO 的三大痛点（梯度耦合、选中概率下降、间隔失控）给出系统性修复，并在文本、数学、语音等多模态任务中取得稳健收益；同时 r₂ 提供了便捷的“安全-创造力”调节旋钮。  \n\n* **局限与展望**  \n  1. 仍需为不同任务手动调参（β、λ、r₂）；  \n  2. 依赖质量可控的偏好对，噪声过大时效果可能受限；  \n  3. 论文聚焦离线对齐，在线 RL 或人机交互中的表现有待验证。  \n\n* **前沿洞见**  \n  - “线性损失 + 梯度解耦”思路可迁移至多模态偏好学习，或催生统一的可控对齐框架；  \n  - r₂ 带来的“拒绝概率可旋钮”特性契合工业对生成安全性的需求；  \n  - 简洁方法即可优于复杂 RL，提示社区重新审视对齐范式，可能推动更可解释、可控的大模型研究。",
      "timestamp": "20250820T0631",
      "title": "Dupo enabling reliable llm selfverification via dual preference optimization"
    },
    {
      "authors": [
        "Chendong Song",
        "Zihan Wang",
        "Frederick Pu",
        "Haiming Wang",
        "Xiaohan Lin",
        "Junqi Liu",
        "Jia Li",
        "Zhengying Liu"
      ],
      "categories": [
        "cs.AI"
      ],
      "content_id": "75b294542de50ddef8658c64c91dfb1632c415baf898ac09768d63b23d222a2d",
      "paper_id": "aa32b7cf4aa6fb154066603f6fe50dc188731061d187f09111a798a389dc4a88",
      "pdf_url": "http://arxiv.org/pdf/2508.14644v1",
      "report": "### XFINBENCH：用于复杂金融问题求解与推理的 LLM 基准\n\n**信号源**：新加坡管理大学计算与信息系统学院；复旦大学可信任具身智能研究院  \n**论文链接**：https://arxiv.org/abs/2508.15861\n\n---\n\n#### 一句话总结  \n作者构建了首个同时覆盖文本、表格与图像的研究级金融数据集 XFINBENCH，并利用 18 个主流模型实证揭示：当前 LLM 在跨期推理与情景规划等核心金融能力上仍显著落后于人类专家。\n\n---\n\n#### 论文摘要  \n金融决策需要复杂推理、多模态信息处理和扎实的专有知识。为系统评估 LLM 的金融能力，作者提出 XFINBENCH——共 4,235 道题目（来自 3 本研究生教材），涵盖文本、表格与图像三种模态，并细分五项关键能力：  \n\n1. 术语理解 (Terminology Understanding)  \n2. 时间推理 (Temporal Reasoning)  \n3. 未来预测 (Future Forecasting)  \n4. 情景规划 (Scenario Planning)  \n5. 数值建模 (Numerical Modelling)\n\n基准包含判断正误、选择题、数值计算三类任务，另构建 3,032 条金融术语知识库辅助可检索增强实验。作者评测 18 款模型：最佳纯文本模型 o1 准确率 67.3%，较人类专家（79.8%）低 12.5 pct；含视觉数据时表现最佳的 claude-3.5-sonnet 仅 64.1%。误差分析指出，计算过程中的四舍五入误差与图表解析“视觉失明”是失败主因。XFINBENCH 因而为金融领域 LLM 研究提供了高难度、系统化的评测平台。\n\n---\n\n#### 核心方法  \n* **数据构建**  \n  * 选取 3 本研究生教材课后题；经 OCR 与人工筛选得到 2,018 道原始题。  \n  * 采用「生成-校验」流程：先用 GPT-4o 将开放题转写为有唯一答案的判断题 / 选择题 / 计算题，再由人工三轮验证，最终保留 4,235 题。  \n  * 每题标注 1–2 个能力标签，并链接 1–3 个相关金融术语；多模态题保留原图表或表格。  \n\n* **评测体系**  \n  * 对 18 个模型统一使用 Chain-of-Thought (CoT)；数值计算任务另测 Program-of-Thought (PoT)，同时报告严格匹配与 ±0.5% 容差 (Acc_ERR@5) 两项指标。  \n  * 构建人类专家基线（硕士背景，闭卷）——综合准确率 79.8%。  \n\n* **知识库检索增强**  \n  * 比较 BM25、Ada Embedding 及理想 “Oracle” 三种注入策略，量化对不同模型与能力的影响。  \n\n* **误差标注**  \n  * 对 400 条计算题与 100 条视觉题进行人工标注，归纳“舍入误差”“公式误用”“视觉失明”等高频失误模式。\n\n---\n\n#### 关键实验结果  \n| 指标 | 纯文本最佳 (o1) | 多模态最佳 (claude-3.5-sonnet) | 人类专家 |\n|------|----------------|--------------------------------|----------|\n| 总准确率 | **67.3%** | **64.1%** | **79.8%** |\n| 术语理解 | 88.9% | 86.4% | 91.0% |\n| 时间推理 | 59.1% | 43.4% | 79.5% |\n| 情景规划 | 60.1% | 47.2% | 75.8% |\n\n* **PoT 并非万能**：对多数模型，PoT 代码执行率低导致计算题表现反而下降。  \n* **视觉题难度陡增**：GPT-4o 在含图题中 35% 错误归因于无法正确识别曲线交点或坐标位置（视觉失明）。  \n* **小模型最受益于知识注入**：Oracle 场景下，Llama-3.1-8B 总分提升约 3 pct，术语理解提升超过 10 pct；GPT-4o 反而偶现“过度依赖”导致推理偏差。  \n\n---\n\n#### 结论与启示  \n1. **可靠金融 LLM 尚需突破**：跨期推理与情景规划是当前主要瓶颈。  \n2. **跨模态解析待攻关**：需融合低层视觉特征与高层金融语义以缓解“视觉失明”。  \n3. **数值推理稳定性**：长链计算易积累舍入误差，结合程序化推理与自检或能改善。  \n4. **轻量模型 + 外部知识**：在算力受限场景，检索增强依旧有效；大模型则亟需更精细的知识筛选与推理控制。  \n5. **研究生态**：XFINBENCH 有望成为金融 NLP/MMLU 新标杆，推动面向风控、定价、合规的下一代金融智能体研究。\n\n---\n\n#### 限制与未来工作  \n* 数据集规模（4k+）相较常规阅读理解数据仍偏小；且目前仅含英文内容，后续可扩展多语言、多市场。  \n* 评测依赖固定输出格式，模型若不遵守格式会被判错；探索更鲁棒的评测脚本值得尝试。  \n\n---\n\n#### 参考指标  \n* 数据集：4,235 题（判断 1,795；选择 761；计算 1,679）  \n* 知识库：3,032 术语 / 1,766 唯一定义  \n* 评测模型：18 个（9 多模态 + 9 纯文本）\n\n---\n\n> **总体评价**：XFINBENCH 设计严谨、覆盖面广，是当前衡量 LLM 复杂金融能力最具挑战的公开基准之一，可为学术与产业界提供重要参考。",
      "timestamp": "20250820T1155",
      "title": "Leangeo formalizing competitional geometry problems in lean"
    },
    {
      "authors": [
        "Rui Wang",
        "Qianguo Sun",
        "Chao Song",
        "Junlong Wu",
        "Tianrong Chen",
        "Zhiyun Zeng",
        "Yu Li"
      ],
      "categories": [
        "cs.LG"
      ],
      "content_id": "6d6c281a253e143c7c35bdeb277df10016bb7c83bc7c742d5c5805dd75e5d385",
      "paper_id": "b0ed40f90a63963943f02309b39fc5cfe30bd640d41f4bb2b27064b5a202b8ff",
      "pdf_url": "http://arxiv.org/pdf/2508.14947v1",
      "report": "### Long Chain-of-Thought Reasoning Across Languages\n**信号源：** University of California, Berkeley  \n**论文链接：** https://arxiv.org/abs/2508.14828  \n\n---\n\n#### 一句话总结  \n作者通过将两套英语长链式推理数据集翻译为法语、日语、拉脱维亚语与斯瓦希里语，并在 Qwen2.5-7B 和 Qwen3-8B-Base 上展开系统实验，揭示“英语枢纽”策略的适用边界，量化多语预训练与小规模监督微调对低资源语言推理能力的显著补益。\n\n---\n\n#### 论文摘要  \n大规模语言模型在英语环境下借助长链式思考（CoT）已展现出色的推理能力，但跨语言效果尚未充分验证。论文将 s1k 与 Bespoke-Stratos-17k 自动翻译成法、日、拉、斯四语，形成 M-s1k（1 k 条）与 M-BS17k（17 k 条），并在此基础上微调 Qwen2.5-7B 与 Qwen3-8B-Base。核心结论：  \n1. “英语枢纽”效果随语言而异——对法语几乎无益，对日语和拉脱维亚语有明显提升，对斯瓦希里语则作用有限。  \n2. Qwen3 的 119 语言大规模预训练缩小了跨语差距，但对低资源语言仍需仅 1 k 条监督微调即可带来超过 30 个百分点的提升。  \n3. 数据质量与规模的取舍具语言依赖性：高资源语种（英语、法语）侧重小而精，低资源语种（拉脱维亚语、斯瓦希里语）则受益于更大但略含噪的语料。  \n\n---\n\n#### 核心方法  \n• 数据集构建：  \n&nbsp;&nbsp;– 使用 Gemini 2.0 Flash 翻译 s1k 与 Bespoke-Stratos-17k，得到五语并行的 M-s1k、M-BS17k。  \n\n• 模型与训练：  \n&nbsp;&nbsp;– 选用 Qwen2.5-7B、Qwen3-8B-Base；  \n&nbsp;&nbsp;– 在 LLaMA-Factory 框架下进行语言特定的监督微调（SFT），并以“语言强制”(language forcing) 作为无额外微调的对照。  \n\n• 评测设置：  \n&nbsp;&nbsp;– 基准集：MATH-500、AIME 2024、IMO、GPQA；  \n&nbsp;&nbsp;– 统一推理参数：temperature 0.6，top-p 0.95，max tokens 16 384；  \n&nbsp;&nbsp;– 采用 GPT-4.1-Mini 自动比对答案，报告准确率。  \n\n• 关键实验设计：  \n&nbsp;&nbsp;1. 英语枢纽效应：构造“问题语言 X / 推理语言 Y”混合语料，分离输入理解与推理生成影响。  \n&nbsp;&nbsp;2. 多语预训练分析：对比 Qwen2.5（29 语、18 T tokens）与 Qwen3（119 语、36 T tokens）在仅提示控制 vs. 语言特定 SFT 下的差异。  \n&nbsp;&nbsp;3. 数据规模探索：同一模型分别在 M-s1k 与 M-BS17k 上微调，比较不同语言对数据规模/质量的敏感性。  \n\n---\n\n#### 实验成果  \n• 英语枢纽并非通用良方  \n&nbsp;&nbsp;– 在 MATH-500 上，Qwen2.5-7B 对法语几乎无提升（76.0 % → 76.4 %）；  \n&nbsp;&nbsp;– 对日语与拉脱维亚语，使用英语推理分别提升约 17 与 14 个百分点；  \n&nbsp;&nbsp;– 对斯瓦希里语提升不足 1 个百分点（52.4 % → 52.6 %）。  \n\n• 多语预训练 + 小样本微调补齐低资源差距  \n&nbsp;&nbsp;– Qwen3-8B-Base 在斯瓦希里语上：仅语言强制 39.4 %，加入 1 k 条斯瓦希里 SFT 后跃升至 73.2 %（+33.8 pp）。  \n\n• 数据规模结论  \n&nbsp;&nbsp;– 英语、法语：M-s1k 已足够，扩大到 M-BS17k 收益有限；  \n&nbsp;&nbsp;– 拉脱维亚语、斯瓦希里语：M-BS17k 能显著优于 M-s1k，说明低资源语种更依赖规模。  \n\n---\n\n#### 总结与反思  \n1. 论文系统比较了长 CoT 的跨语言迁移机制，提出“高 / 中 / 低 资源语言三分层”规律。  \n2. 多语大规模预训练与极小监督微调互补：前者降低门槛，后者在低资源场景仍不可或缺。  \n3. 局限性：  \n&nbsp;&nbsp;– 自动翻译的数据仍含噪或文化偏差；  \n&nbsp;&nbsp;– 仅覆盖四种非英语语言，难以概括全部语言谱系；  \n&nbsp;&nbsp;– 评测完全依赖自动判分，仍需人工复核。  \n\n---\n\n#### 前沿展望  \n• 扩展至更多低资源语言，或探索“自译-自检”生成高质量多语推理数据。  \n• 企业可基于小规模本地化微调快速部署多语推理助手，降低成本。  \n• 研究层面强调“数据-预训练-微调”协同，而非单一依赖英语枢纽或盲目扩大模型规模。",
      "timestamp": "20250820T1017",
      "title": "Linear preference optimization decoupled gradient control via absolute regularization"
    },
    {
      "authors": [
        "Yijin Chen",
        "Wenqiang Xu",
        "Zhenjun Yu",
        "Tutian Tang",
        "Yutong Li",
        "Siqiong Yao",
        "Cewu Lu"
      ],
      "categories": [
        "cs.RO"
      ],
      "content_id": "672d689594c77a1f1107e8619aa036e7d2e197db77b656fa55b630cd253199d8",
      "paper_id": "dbe7b7d455820629022a319ce491ee72808ced54a1f191a7f0bc216b344dcc70",
      "pdf_url": "http://arxiv.org/pdf/2508.14441v1",
      "report": "### LeanGeo: Formalizing Competitional Geometry Problems in Lean\n\n**信号源**：Moonshot AI、Numina、北京大学、多伦多大学  \n**论文链接**：https://arxiv.org/abs/2508.14644\n\n---\n\n#### 一句话总结  \n作者构建了首个可在 Lean 4 中严谨表达与验证奥赛级几何题的统一系统 LeanGeo，并配套发布了 122 题的 LeanGeo-Bench 基准，全面揭示了现有大模型在几何逻辑推理上的短板。\n\n---\n\n#### 论文摘要  \n1. **背景**：几何证明历来是检验 AI 推理能力的难点，现有系统多在独立的几何形式体系内运行，难以与代数、数论等其他分支结合，且缺乏可机器验证的严谨性。  \n2. **目标**：在 Lean 4 定理证明器内部，建立一个既能覆盖竞赛级几何知识、又能与 Lean 生态深度融合的通用几何库与评测集。  \n3. **方法**  \n   • 手工形式化 260 条高层几何定理，形成 LeanGeo 库；  \n   • 基于国际奥数（IMO）与教材题目构建 LeanGeo-Bench，共 122 题；  \n   • 设计 SMT + Lean 元编程的混合证明策略，并评测多款主流 LLM；  \n   • 通过自动合成新定理 + 强化学习，初步提升模型在该环境中的证明能力。  \n4. **发现**：现阶段顶尖 LLM 在 LeanGeo-Bench 的 pass@4 最高仅 27%，无一能解 62 道奥赛级难题（19 道 Olympic Problem + 43 道 IMO），显示出显著研究空间。  \n5. **产出**：开源 LeanGeo 库与基准，供社区后续研究。\n\n---\n\n#### 核心方法  \n**整体框架**  \n1. **形式系统**：以 System E 公理为基底，增补 52 个几何对象定义与 9 条基础公理，形成可与 Mathlib 无缝衔接的坐标无关几何语言。  \n2. **定理库构建**：人工自顶向下书写并机证 260 条“人类可读”的高阶定理，借助 LeanSMT 自动填补低层逻辑细节。  \n3. **基准设计**：收集 IMO 2000-2025 全部几何题及教材、合成题目，生成 Lean 版本题库 LeanGeo-Bench，并给出 43 条机审通过的参考证。  \n4. **评测流程**：以“一阶段 Fine-Eval”自动调用 Lean 服务器检验模型输出是否可被内核接受，确保零容忍错误。\n\n**关键技术细节**  \n• **SMT-增强 tactic（`esmt`）**：将本地上下文 + System E 公理一次性送入 CVC5 做不可满足性检查，若返回 unsat 则目标得证，简化分类讨论。  \n• **命令缓存与依赖图**：对 SMT 命令做缓存，维护全局 metavariable 依赖图，避免重复翻译，显著加速推理。  \n• **“注入式”强化学习**：先用 LLM 合成 5 000 条新定理-证明对，经 Lean 验证后划分为激活集与提示集；再在 Kimina RL 框架中随机抽取 10 条定理放入 prompt，训练模型在嘈杂上下文中自选工具，成功率由 2.52% 提升至 10.92%。\n\n---\n\n#### 实验成果  \n* **LLM 现状评测**  \n  在 LeanGeo-Bench 上，GPT-o4-mini 的 pass@1 为 19.67%，Gemini 2.5 Pro 的 pass@4 为 27.05%；所有模型在 62 道奥赛级题目（OP 19 + IMO 43）上全部失利，凸显几何推理的困难度。  \n\n* **库内 RL 提升**  \n  经过两阶段 RL 训练，模型在内部验证集的整体证明成功率由 12.5% 提升到 40%，在公开基准的 pass@1 提升到 10.92%，证明“定理注入”策略有效。\n\n---\n\n#### 总结与反思  \n* **结果总结**：LeanGeo 成功把依赖图形直觉的平面几何迁移进 Lean 的形式世界，提供了可重用、可扩展的高层定理库和严格评测基准，奠定了跨领域数学自动化的基础。  \n* **局限性**  \n  1. SMT 证明目前依赖外部 CVC5 证书，尚未全部回放进 Lean 内核，完全可信度有待提升。  \n  2. 通用 SMT 缺乏几何专用启发式，规模增大时性能下降。  \n  3. RL 注入策略仍依赖长 prompt，模型对库中定理的“内化”程度有限。  \n* **前沿展望**  \n  • **研究方向**：借助 LeanGeo 统一语域，可探索“几何-代数-数论”跨域推理算法，或开发带几何启发的专用 SMT／面积法 tactic。  \n  • **工业应用**：在 CAD、机器人路径规划、教育软件等场景，严谨几何证明可用于自动验证设计正确性、生成可交互证明；LeanGeo 让这一流程更可控。  \n  • **学科意义**：几何一直是自动定理证明的“硬骨头”。LeanGeo 通过人类可读的定理库 + 机器可检的严格性，为 LLM 时代的“类人”数学推理提供了新的落脚点，预示大型模型将从“会算”进化到“会证”。",
      "timestamp": "20250820T0553",
      "title": "Fbi learning dexterous inhand manipulation with dynamic visuotactile shortcut policy"
    },
    {
      "authors": [
        "Zhihan Zhang",
        "Yixin Cao",
        "Lizi Liao"
      ],
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "content_id": "3e2d3a0242339e104b0606de737e2965ce734c6b44e600750c03208e0d94e600",
      "paper_id": "e6eb51962a02903680dc71af441570d90f85b592fc0c64f5e92b274600bdf395",
      "pdf_url": "http://arxiv.org/pdf/2508.15861v1",
      "report": "### Improving LLMs for Machine Translation Using Synthetic Preference Data  \n**信号源：** University of Ljubljana, Faculty of Computer and Information Science  \n\n**一句话总结**  \n通过自动生成“优/劣”翻译对并用直接偏好优化（DPO）微调，仅用 9B 参数模型即可在英语→斯洛文尼亚翻译上逼近甚至在部分场景超越更大模型，显著减少语言和截断错误。  \n\n**论文摘要**  \n作者针对资源稀缺的斯洛文尼亚语机器翻译，提出一种无需人工标注的改进流程：先用两种开源 LLM（GaMS-9B-Instruct 与 EuroLLM-9B-Instruct）翻译英文维基和新闻文章，再依据启发式规则与 COMET 评分自动标出优劣翻译对，最后用 DPO 训练 GaMS-9B-Instruct。新模型在 SloBench 公开基准及未见过的维基/新闻文章上，都明显优于原始模型，并能稳定避免输出非目标语或文本截断。该方法语言无关，可推广到其他低资源语言。  \n\n**核心方法**  \n* 方法框架：  \n  1. 双模型翻译：用两个独立 LLM 为同一英文文本生成两个斯洛文尼亚语候选。  \n  2. 质量判别：  \n     • 规则筛除明显错误（非目标语言、截断、格式前缀）。  \n     • 对剩余候选用 COMET 评分，若分差 ≥ 0.05，则高分为“优”，低分为“劣”。  \n  3. 构建偏好数据集：融合规则错误对与 COMET 质量对，得到约 3.5 万条“优/劣”配对。  \n  4. DPO 微调：以 GaMS-9B-Instruct 为基线，在偏好数据上做 Direct Preference Optimization，通过最小化“优/劣”对数似然比直接对模型进行偏好对齐。  \n\n* 技术细节：  \n  1. 错误检测自动化  \n     • 语言识别：FastText 断定输出是否为斯洛文尼亚语。  \n     • 截断检测：若译文长度不足原文 50% 即判定为截断。  \n     • 格式噪声：程序化添加／去除“Slovene translation:” 等前缀构造显式偏好对。  \n  2. 参数高效训练  \n     • 采用 LoRA，仅微调少量参数即可适配 9B 模型。  \n     • 使用 DeepSpeed ZeRO-Stage-2 + Gradient Checkpointing，在 16×A100 GPU 上完成 3 epoch 训练。  \n  3. 超参选择  \n     • 网格搜索 β∈{0.1, 0.2} 与学习率∈{1e-6, 4e-7, 1e-7}，最终选 β = 0.1, lr = 1e-6（验证损失最低 0.255）。  \n\n**实验成果**  \n* **维基 & 新闻翻译质量大幅提升**：在 500 篇未见维基文章和 CC-News 文章上，新模型 COMET 分别提升至 0.757 / 0.715，较基线 GaMS-9B-Instruct 提高约 0.04；同时将“非目标语言+截断”综合错误率从 13 % 降至 0.8 %。  \n* **公开基准逼近大模型**：在 SloBench 英→斯洛文尼亚任务中，GaMS-9B-DPO-Translator 的平均 BLEU 从 0.277 提升至 0.281，总体得分与 3 倍参数量的 GaMS-27B-Instruct 接近，与同参数量的 EuroLLM-9B-Instruct 大体相当。  \n\n**总结与反思**  \n* 结果总结：论文展示了一条低成本、自动化的机器翻译增益路线——利用双 LLM 互译 + 自动优劣判别 → DPO 微调，可显著减少低资源语言翻译中的粗暴错误，并带来稳健的质量提升。  \n* 局限性：  \n  • 偏好数据主要来源于维基和新闻，风格/领域覆盖仍有限；  \n  • 评估依赖自动指标与合成错误检测，对语义细微差异的人工验证不足；  \n  • 仅验证 9B 规模，迁移到更大模型或其他语言需重新调参与资源投入。  \n* 前沿见解：  \n  • 研究方向：a) 将“多模型互译+自动筛选”扩展为多语言、多域 Curriculum DPO；b) 结合可微指标（如 COMET 作为奖励函数）尝试 GRPO 或混合 RL 策略；c) 在数据稀缺领域（方言、专业术语）快速自举高质量译文资源。  \n  • 工业应用：可为本地政府、教育及媒体批量翻译公共语料，节省商业 API 费用；同法可用于企业内部文档跨语迁移，从而构建专属多语知识库。  \n  • 领域影响：证明了“偏好对齐”不仅适用于对话质量，同样能解决传统 NMT 模型难以捕捉的细粒度翻译偏好，或将促成新一代“偏好驱动”机器翻译体系，把 RLHF/DPO 方法正式引入 MT 主流流程。",
      "timestamp": "20250820T1523",
      "title": "Xfinbench benchmarking llms in complex financial problem solving and reasoning"
    },
    {
      "authors": [
        "Sk Miraj Ahmed",
        "Umit Yigit Basaran",
        "Dripta S. Raychaudhuri",
        "Arindam Dutta",
        "Rohit Kundu",
        "Fahim Faisal Niloy",
        "Basak Guler",
        "Amit K. Roy-Chowdhury"
      ],
      "categories": [
        "cs.LG"
      ],
      "content_id": "afb0bd97b9a98cdc21360bcc5b21d17ca77dc014e2ad566b41637ae36e928616",
      "paper_id": "4343fcfd963116471c0c7bf6dc8dd8af6ef552f44c04f5cb32aa35c10809b8cf",
      "pdf_url": "http://arxiv.org/pdf/2508.15127v1",
      "report": "### DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization  \n**信号源：** ByteDance Seed、南京大学  \n\n---\n\n#### 一句话总结  \nDuPO 提出一种“已知-未知”分解的广义对偶学习框架，让大模型自己给自己打分，实现无需人工标注、跨任务通用的强化学习优化。\n\n---\n\n#### 论文摘要  \n当前的 RLHF 依赖昂贵的人类偏好，RLVR 又受限于必须可验证的任务，传统对偶学习则要求严格可逆，难以覆盖多数开放式场景。DuPO 通过将原始输入拆分为“已知部分” x_k 与“未知部分” x_u，仅要求对偶任务重建未知部分，从而绕过“完全可逆”的硬约束，并大幅降低对偶任务难度。一旦重建成功，即可把重建误差转化为自监督奖励，并用 GRPO 等策略梯度方法反向优化原任务。实验证明，该方法在 756 个翻译方向上平均提高 2.13 COMET，在三大数学推理基准上平均提升 6.4 个百分点；在推理时充当重排序器，还可把小模型性能额外提升 9.3 点，展示了 DuPO 的通用性与可扩展性。\n\n---\n\n#### 核心方法  \n1. **输入拆分**：将原任务输入 x 划分为已知 x_k 与未知 x_u。  \n2. **原任务（Primal）**：模型根据完整输入生成输出 y。  \n3. **对偶任务（Dual）**：模型利用 y 与 x_k 重建 x_u，而非重建整个 x。  \n4. **奖励计算**：用重建误差 d(x_u, \\hat{x}_u) 作为自监督奖励，误差越小奖励越高。  \n5. **偏好优化**：通过 GRPO（或兼容的 PPO 系列算法）更新模型，使期望奖励最大化。  \n\n技术要点：  \n- **已知-未知选择策略**：  \n  • 数学推理任务中自动将题目中部分数字替换为变量；  \n  • 翻译任务中采用回译（反向翻译）保证语义一致性。  \n- **单模型双角色**：同一 LLM 同时执行原任务与对偶任务，避免双模型能力不对称。  \n- **训练-推理两用**：训练阶段提供奖励信号；推理阶段用对偶准确率对候选答案重排序，可即时提升输出质量。\n\n---\n\n#### 实验成果  \n\n| 任务 | 基线模型 | DuPO 提升 | 结果摘要 |\n| ---- | -------- | --------- | -------- |\n| 多语翻译（28 语 756 方向） | Seed-X-7B-Instruct | +2.13 COMET | 综合得分 64.66，接近 DeepSeek-R1-0528（64.80），并超越部分超大闭源模型 |\n| 数学推理（AMC23/AIME24/AIME25） | Qwen3-4B | +6.4 pp | 平均准确率由 77.2 % 提升至 83.6 %，反超 DeepSeek-R1-0120 |\n| 推理期重排序 | Qwen3-4B | +9.3 pp | 无需再训练即可把平均准确率从 68.4 % 提升到 77.7 % |\n\n---\n\n#### 总结与反思  \n* **结果总结**  \n  DuPO 证明了“部分重建即可自评”的思想在翻译与数学两种截然不同的任务上均能带来稳定收益。方法省去了人工标注，突破了 RLVR 仅适用于可验证任务的限制。  \n* **局限性**  \n  1. 已知-未知划分目前依赖启发式规则，尚未在更开放的对话、代码生成等任务中验证；  \n  2. 论文实验集中在 7B 及以下规模，超大模型上的收益与稳定性仍待评估；  \n  3. 构造对偶任务与重排序会带来额外计算开销。  \n* **前沿见解**  \n  - 自动学习“最信息化未知组件”选择器，可让框架更通用；  \n  - 与 Agent 框架结合，在多步推理、工具调用中动态生成自监督信号；  \n  - 在工业场景（翻译、代码审计、数理计算）中，可作为“自检-重排序”模块直接上线，持续自优化。  \n\nDuPO 为“自我验证大模型”提供了可行范式——只要能设计出信息可还原的对偶问题，就能让模型产生可靠的内生偏好信号，或将成为后 RLHF 时代的重要替代方案。",
      "timestamp": "20250820T2329",
      "title": "Towards sourcefree machine unlearning"
    }
  ]
}